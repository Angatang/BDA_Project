{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BbcCmcA758Lg","executionInfo":{"status":"ok","timestamp":1669515354214,"user_tz":300,"elapsed":51826,"user":{"displayName":"Angadsingh Prabjotsingh Kanvar","userId":"01993222396421061521"}},"outputId":"2ceb145f-e3c1-4698-e87e-fc92c5253d93"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyspark\n","  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n","\u001b[K     |████████████████████████████████| 281.4 MB 45 kB/s \n","\u001b[?25hCollecting py4j==0.10.9.5\n","  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n","\u001b[K     |████████████████████████████████| 199 kB 42.8 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=2efc9ad6b68a401879a3692d626a852d856b0c86a2116d8afe7c37d39d8fb210\n","  Stored in directory: /root/.cache/pip/wheels/42/59/f5/79a5bf931714dcd201b26025347785f087370a10a3329a899c\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"]}],"source":["pip install pyspark"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tK5-tCv92vpY","executionInfo":{"status":"ok","timestamp":1669515355014,"user_tz":300,"elapsed":829,"user":{"displayName":"Angadsingh Prabjotsingh Kanvar","userId":"01993222396421061521"}},"outputId":"fdccdb7b-02f6-4177-fc6b-8af5a8722658"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.ml import feature, regression, evaluation, Pipeline\n","from pyspark.sql import functions as fn, Row\n","import matplotlib.pyplot as plt\n","from pyspark.ml.feature import Tokenizer\n","from pyspark.ml.feature import CountVectorizer\n","import numpy as np\n","import pandas as pd\n","import os\n","spark = SparkSession.builder.getOrCreate()\n","sc = spark.sparkContext"],"metadata":{"id":"VrJREGl76fMn","executionInfo":{"status":"ok","timestamp":1669515366294,"user_tz":300,"elapsed":11284,"user":{"displayName":"Angadsingh Prabjotsingh Kanvar","userId":"01993222396421061521"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["test = spark.read.csv('/test.csv', header=True, inferSchema=True)\n","#test <- spark.read.csv('test.csv', header=True, inferSchema=True)"],"metadata":{"id":"FV8cxeguOLWS","executionInfo":{"status":"ok","timestamp":1669515375828,"user_tz":300,"elapsed":9545,"user":{"displayName":"Angadsingh Prabjotsingh Kanvar","userId":"01993222396421061521"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["train = train_df.toPandas()"],"metadata":{"id":"rgalSZjweLEg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.head()"],"metadata":{"id":"J5wuQfvhfJBt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"l8LiODNsfRzj"},"execution_count":null,"outputs":[]}]}